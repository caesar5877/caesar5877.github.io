
微服务开发的整体流程

**1. 开发阶段 (Development Phase)**
在项目拿到并且完成系统分析设计之后，即进入开发阶段。
*   各个开发组的成员会认真开发。
*   他们负责开发自己担当的服务内容，例如：
    *   开发组可能在开发**用户的微服务**。
    *   其他服务可能包括**新闻的微服**、**行情博客**(行情微服）、以及**博客**等等的微服。
*   开发组分别开发自己担当的微服务模块。

**2. 持续集成与交付管道 (Pipeline and Image Management)**
开发完成之后，代码需要通过一个**拍不烂管道**(Pipeline).
*   **代码管理：** 在管道内部，需要进行代码上传和管理。所有的系统代码是在管道里面的**扣空面中**进行管理。
*   **打包测试：** 成功进行打包测试后，成品会被部署到 ECR。
*   **ECR 的作用：** **ECR (Elastic Container Registry)** 负责整体的 Docker 镜像的**版本管理**。所有成品后的镜像都在 ECR 上进行管理。

**3. 部署与分发 (Deployment and Distribution)**
ECR 管理完版本后，会进行推送。
*   **ECS 接收与部署：** **ECS 的服务**接受到最新的推送消息后，会将最新的镜像进行部署。
*   **部署算法：** 部署可以采用多种算法，例如**滚动部署**(Rolling Deployment）或**蓝绿部署**(Blue/Green Deployment).
*   **服务分发：** 部署完成后，会采用 **80后自三的服务的方式**(通常指服务发现）进行分发。用户最终就可以使用该服务。

**4. 架构与优势 (Architecture and Benefits)**
*   **ECS 承载：** 在 ECS 服务当中，可以部署**多个不同的微服**都存在其中。例如，可以包含用户模块、行情模块、新闻模块、博客模块等。
*   **微服务带来的好处：** 如果其中哪个模块出现 bug，只有负责修改该模块或微服务的程序组需要修改，**而不会对其他的微服务产生影响**。这是微服务开发带来的主要好处。

---
### Lesson 5 ECS服务结构
您的查询是关于 AWS ECS(Elastic Container Service）的服务结构和使用步骤的中文解释。下面将根据您提供的资料，详细阐述 ECS 的四个核心概念和使用 ECS 的四个步骤。

**ECS 服务结构基础概念 (AWS ECS Service Structure Core Concepts)**

ECS 的服务结构描述了部署和运行容器化应用所需的基础概念。

1.  **集群 (Cluster):**
    *   集群是 ECS 部署的**最外层概念**，是运行服务器的集合。
    *   在部署 ECS 之前，首先需要在系统中生成一个服务器集群。
    *   集群有两种主要类型：
        *   **黑盒类型 (Fargate):** 用户不需要管理底层的设施。
        *   **EC2 类型:** 用户需要维护自己的 **EC2 实例**。

2.  **容器 (Container):**
    *   容器是直接与业务挂钩的概念。
    *   容器是指将具体的服务(如用户服务、新闻服务、博客服务）**封装成一个独立的 Docker 镜像**。
    *   系统开发人员的工作重点是开发业务逻辑，并将其封装成一个 Docker 容器镜像。
    *   容器的开发是实际的业务开发工作。

3.  **任务定义 (Task Definition / Task):**
    *   任务定义决定了一个服务中**应该运行哪些容器**。
    *   任务 (Task) 是通过定义 **Task Definition** 来生成的。
    *   一个任务中可以包含**一个容器**(例如：用户 Task 包含用户容器).
    *   一个任务中也可以包含**多个容器**(例如：会员 Task 可以包含用户管理容器、数据库维护容器、用户支付容器).
    *   **建议：** 为了便于理解和项目管理，**最好一个任务中只包含一个容器**。

4.  **服务 (Service):**
    *   服务定义了在集群中**要部署的具体应用**。
    *   服务是根据系统设计决定的，例如部署用户服务、新闻服务、博客服务等。
    *   可以理解为，如果部署的是微服务，那么每一个微服务就是一个 **Service**。
    *   服务可以定义**多个任务**，并且可以配合 **LB (负载均衡)** 和 **Auto Scaling** 来实现更大的扩展性 (Scale Out)。

**ECS 的四个使用步骤 (Four Steps for Using ECS)**

小马提供的 ECS 使用步骤共有四个，它们定义了部署 ECS 应用的顺序：

1.  **第一步：容器的定义 (Container Definition)**
    *   这涉及**系统设计和应用开发**。
    *   核心工作是将微服务应用**打包成 Docker 容器**(如用户容器、行情容器等).
    *   这样做的目的是让每个小的功能单独打包，提供单一功能，降低系统的耦合性，并便于自动测试。
    *   开发人员的日常工作就是开发容器内的业务逻辑。

2.  **第二步：任务的定义 (Task Definition)**
    *   在 ECS 中定义 ECS 任务，并**指定刚打包好的 Docker 容器**作为该任务的容器。
    *   可以指定一个或多个容器，但建议只包含一个容器。
    *   在任务定义时，还需要指定任务的**执行方式**以及所需的**资源**，包括 CPU 和内存的分配。

3.  **第三步：集群的定义 (Cluster Definition)**
    *   在部署任何任务或服务之前，必须先定义集群。
    *   集群定义是为整体容器搭建一个**运行环境**并**分配资源**。
    *   需要定义采用哪个 VPC 和 VPC 内的哪些子网。
    *   如果使用的是 **EC2 集群**，还需要规划和定义集群中 EC2 服务器的数量、规格 (size)、CPU 和内存的分配。

4.  **第四步：启动服务 (Service Startup)**
    *   在第二步定义好任务之后，就可以启动服务了。
    *   可以选择**单独启动一个任务**来提供服务。
    *   也可以定义一个**服务 (Service)**，并在该服务中定义多个任务，然后启动服务。
    *   在启动服务时，还可以加上 **LB** 进行负载均衡，或加上 **Auto Scaling** 实现更大的扩展和 Scale Out 功能。

<!--**总结比喻：**

如果将 ECS 服务结构比作建造一座现代化的工厂，那么**集群 (Cluster)** 就是工厂的土地和基础设施(决定了是租用黑盒土地还是自己维护 EC2 厂房).**容器 (Container)** 则是工厂里生产的零部件或产品(业务逻辑).**任务定义 (Task Definition)** 相当于规定了某个工作台(Task）上要安装哪种生产线(Container），以及需要多少电力和工人(CPU/内存).最后，**服务 (Service)** 就是实际的生产线调度系统，它负责根据需求启动或停止多个工作台(Task），并确保产品可以分发出去(LB/Auto Scaling).
-->
---
### 建立ECS必要角色
这是一个关于如何在 **AWS ECS (Amazon Elastic Container Service)** 中建立必要 **IAM 角色 (Identity and Access Management)** 的详细说明。这些角色的定义是正式使用 ECS 之前总体规划的关键步骤。

### 中文解释：建立 AWS ECS 所需的 IAM 角色

在 AWS ECS 中，不同的组件需要执行不同的功能，因此必须事先定义好相应的 IAM 角色来赋予它们执行这些任务的权限。整个过程是通过 AWS 管理控制台中的 IAM 服务来完成的。在创建角色时，首先需要选择 **ECS 服务**。

根据来源信息，这里定义并创建了四种必要的角色：

#### 1. EC2 角色 (EC2 Role)

**目的：** 这是为 ECS 服务的 EC2 实例定义的角色。
**创建步骤与权限：** 在创建角色时，选择 ECS 服务下的 EC2 角色选项。该角色默认具备多项权限，包括**日志写入权限、EC2 权限、ECR (Elastic Container Registry) 权限以及 ECS 权限**。

#### 2. ECS 角色 (ECS Role)

**目的：** 这是 ECS 容器本身的角色，也称为 **ECS 的容器角色**。它负责管理和协调容器的运行。
**权限重点：** 此角色会自动加载所需的权限，通常包括 **EC2 权限、ELB (Elastic Load Balancing) 权限以及 ELBv2 权限**。拥有 ELB 权限是因为当部署多台实例时，需要在它们前面添加 ELB 来进行负载均衡。

#### 3. Autoscaling 角色 (Autoscaling Role)

**目的：** 创建此角色是为了实现 **自动扩展 (skill out)** 功能。当业务需求变化时，EC2 实例集需要自动扩展或收缩。
**创建步骤：** 在创建角色时，选择 ECS 服务下的第三个选项，即 **Autoscaling 的 Parton** (伴侣/合作者) 角色。

#### 4. 任务角色 (Task Role)

**目的：** 这是针对 **每个具体的 ECS 任务 (Task)** 定义的角色，用于控制该任务能够存取哪些 AWS 资源。
**灵活性和权限：** **这个角色具有高度的灵活性**。每个任务存取的 AWS 资源是不同的，因此它们的权限需求也不同。
*   例如，一个用户组件可能需要存取 **DynamoDB (DB)**，那么它就需要具备 DB 的读取和写入权限，而不需要 S3 权限。
*   另一个行情组件可能需要用到 **S3 服务**，那么它的 Task 角色就应具备对 S3 的读写权限。
*   任务的具体执行权限是**根据您的任务需求来确定和添加的**。在创建时，选择 ECS 服务下的最后一个选项，即任务角色。

#### 总结操作习惯

在创建角色时，有一个重要的操作习惯：为角色起一个明确的名称，并**添加标签**，这是一个好的习惯。


<!--### 总结比喻

我们可以将建立 **ECS 所需的 IAM 角色** 比作**组建一支高度专业化的工程建设团队**。

一个大型的 ECS 项目就像一栋复杂的摩天大楼。为了确保施工过程(ECS 运行）顺利且安全，每个“工人”和“设备”都需要有明确的许可和职责：

1.  **EC2 角色** 就像提供基础的施工机械和场地工人。他们有进入工地(EC2）、使用材料仓库(ECR）和在总指挥部(ECS）登记的基本许可。
2.  **ECS 角色** 就像项目总指挥官。他不仅需要基础许可，还必须持有连接所有子项目(EC2 实例）并确保交通顺畅(通过 **ELB 负载均衡**）的特殊协调和管理许可证。
3.  **Autoscaling 角色** 就像项目的人力资源和物流经理。他的职责是根据施工进度和需求(流量），及时自动地增派或减少工人与设备。
4.  **任务角色** 就像具体的专业工种的**工作许可**。电工(DB 任务）只被允许处理电路相关的材料和工具(DB 权限），而管道工(S3 任务）只被允许处理管道系统(S3 权限).**正是这些精确分配的专业工作许可，确保了每个任务只能访问它所需的资源，从而保证了施工过程的效率和安全**。

这四种角色共同构成了 ECS 运行的权限基础，确保了系统能够高效、安全地执行其定义的功能。
-->
---
这是一个关于 **AWS ECS 课程所采用的网络结构设计** 的详细解释，该网络拓扑结构是您在开始部署容器服务之前必须提前搭建好的基础环境。

### AWS ECS 课程所采用的网络结构设计(中文解释）

在正式部署生产环境之前，定义和搭建好一套完整的网络拓扑结构至关重要。本套 ECS 课程采用的网络结构与讲师的 AWS 入门课程所使用的结构是相同的。

**以下是这套网络结构的关键组成要素及其作用：**

#### 1. 核心网络环境 (VPC)
首先，您需要建立一个独立的 **AWS VPC (Virtual Private Cloud)**。VPC 是您在 AWS 云中拥有的隔离网络环境。

#### 2. 公网出入口 (Internet Gateway)
为了允许外部世界(互联网）的流量进来，同时让您的公有实例能够出站访问互联网，需要设立一个 **Internet Gateway (互联网网关)**。

#### 3. 私网对外通信 (NAT Gateway)
为了保证部署在 **私有网络** 中的实例也能够安全地通往互联网(例如，下载更新、连接外部服务），您需要在公有网络中设立一个 **NAT Gateway (网络地址转换网关)**。

#### 4. 网络划分与冗余 (Multi-AZ Subnets)
网络必须划分为公有和私有两大部分，并且为了实现高可用性和灾难恢复，这两类网络都必须是 **多 AZ (Availability Zone)** 版本：

*   **公有网络 (Public Network)：** 容器或服务如果需要直接暴露给互联网，可能会部署在这里。
*   **私有网络 (Private Network)：** 用于部署不需要直接暴露的服务或后端组件，保证更高的安全性。
*   **多 AZ 配置：** 网络结构必须跨越至少两个可用区(例如，AZEAC1 和 AZEAC2).这意味着公有网络和私有网络在不同的物理位置都有副本，这确保了如果一个 AZ 出现问题，服务仍可以在另一个 AZ 正常运行。

**总结**

在学习接下来的 ECS 部署课程之前，您需要在您的 AWS 账户中依次完成以下网络结构的搭建：

1.  建立一个专属的 **VPC**。
2.  建立具备多 AZ 版本的 **公有网络**。
3.  建立具备多 AZ 版本的 **私有网络**。
4.  设立一个连接到互联网的 **Internet Gateway**。
5.  在公有网络中建立一个 **NAT Gateway**，以保证私有网络可以通往互联网。

<!--### 总结比喻

我们可以将这套 ECS 网络结构比作**建设一个高度安全且功能完备的科技园区**。

1.  **VPC** 就像这个科技园区的 **边界和围墙**，它定义了所有内部资源的范围和隔离性。
2.  **Internet Gateway (互联网网关)** 就像园区设立的**主大门**。所有外部访客(互联网流量）必须通过此门进出，允许必要的公共服务(如网站前端）直接与外界交流。
3.  **公有网络** 就像园区内的**接待大厅和公开展示区**，所有需要直接面对公众的服务部署在这里，便于外部直接访问。
4.  **私有网络** 就像园区内的**核心研发中心和数据机房**。这些地方高度敏感，默认不允许外部流量直接进入，保证了核心数据的安全。
5.  **NAT Gateway (NAT 网关)** 就像这个研发中心的**专用对外采购通道**。研发人员(私有实例）可以安全地通过这个通道向外部供应商(互联网）获取工具或软件更新，但外部人员无法通过这条通道闯入研发中心。
6.  **多 AZ (Multi-AZ) 配置** 则确保了园区拥有**两套完整的备份设施**。如果园区的一半因为地震或停电而瘫痪，另一半可以立即接管所有功能，确保整个园区的服务永不中断。
-->
---
这是一个关于 **如何通过 AWS 管理控制台创建 ECS 集群** 的详细中文解释。该过程旨在为后续定义服务和任务打下基础。

### 中文解释：创建 AWS ECS 集群

本次课程的主题是创建一个 ECS 集群(Cluster).集群是您定义服务、任务和容器的基础环境。

#### 1. 生产环境与学习环境的方法选择

在正式开始实战之前，需要明确两种创建方法：

*   **生产环境 (Production)：** 在生产环境中，尤其需要跨多个 AWS 区域(Region）部署时(例如东京、大阪、新加坡），通常会使用 **CloudFormation** 等自动化程序来自动生成集群，以避免手动建立的繁琐。
*   **学习环境 (Learning)：** 讲师建议初学者通过 **AWS 管理控制台** 手动创建集群。这样做的目的是让学员“知其然知其所以然”，了解系统内部执行的每一个步骤，而不是依赖于 AWS 的“开始使用”按钮自动完成所有后端设置。

#### 2. ECS 的两种启动模式与集群划分

ECS 支持两种主要的启动模式，并且如果您计划使用这两种模式，则需要为它们分别建立不同的集群：

1.  **Fargate 启动模式：** AWS 托管模式，您无需管理底层的 EC2 实例。
2.  **EC2 启动模式：** 您需要自行提供和管理底层 EC2 实例。

---
下面是针对这两种模式的集群创建步骤：
### 第一步：创建 Fargate 集群

Fargate 集群的创建相对简单，因为它不需要配置底层实例。

*   **操作：** 在 ECS 管理页面中，选择“创建集群”并选择第一种类型，即为 **Fargate 启动模式** 做准备的集群。
*   **命名与网络：** 为集群命名(例如：`深学 AWY ECS Farget claster`).
*   **VPC 配置：** 不创建新的 VPC，而是使用 **已经搭建好的现有 VPC**。
*   **好习惯：** 添加标签(Tag）是一个很好的习惯。

创建成功后，Fargate 集群即完成。

---

### 第二步：创建 EC2 集群 (包含资源配置)

EC2 集群需要更多的资源配置，并且会产生费用。讲师强调，EC2 集群仅用于本次演示目的，完成后会立即删除以节省开支。

1.  **基础配置：**
    *   选择创建集群的第二种类型：**EC2**。
    *   为集群命名(例如：`深学 AWS ECSECD classer`).
2.  **实例与容量配置：**
    *   **购买模式：** 可以选择按需实例 (On-Demand) 或 Spot 实例。虽然 Spot 实例更便宜且可以在生产环境中使用，但本次演示选择 **按需实例**。
    *   **实例类型：** 演示选择免费套餐(`T2.micro`).但需注意，免费套餐的内存较少，可能无法运行复杂的任务。
    *   **实例数量：** 设置启动 **两台** EC2 实例。
    *   **AMI (镜像)：** 选择默认的 Amazon Linux 2 AMI。
    *   **磁盘大小：** 必须设定最小为 **30 GB**。
    *   **密钥对 (Key Pair)：** 可以选择不创建，因为本次演示中不会通过 SSH 登录实例。
3.  **网络和安全配置：**
    *   **VPC：** 使用现有的 `深学AWSVPC`。
    *   **子网 (Subnets)：** 将实例部署到 **外网区(公有网络）**，并选择两个不同的可用区子网(例如 `EA` 和 `ECC`）以实现冗余。
    *   **公有 IP：** 启用自动分配公有 IP。
    *   **安全组 (Security Group)：** 选择默认的外网安全组，它通常允许访问 80 或 443 端口，以便部署在集群上的应用可以被外部访问。
4.  **权限与完成：**
    *   **容器 IAM 角色：** 选择预先创建好的容器 IAM 角色.
    *   **创建过程：** AWS 会在后台通过 CloudFormation 完成资源创建。
5.  **结果验证：**
    *   创建完成后，通过 EC2 控制台可以看到后台正在启动 **两台** `T2.micro` 类型的 EC2 实例。
    *   这两台 EC2 实例中已经安装了 **ECS 代理 (ECS Agent)**，该代理负责管理 Docker 容器的生命周期。
    *   **注意：** 由于不立即使用 EC2 集群，为节省费用，该集群和实例将被立即删除。



<!--### 总结比喻

我们可以将创建 ECS 的两种集群比作**建设两种不同型号的工厂**，用于生产集装箱(容器）：

1.  **Fargate 集群 (全托管工厂)：** 这就像您租用了一个**现代化的、全自动的生产线**。您只需要提供蓝图(任务定义）和原材料(容器镜像).您无需关心工厂的供电、维护、工人数量(EC2 实例管理），AWS 已经帮您全部搞定。它**启动快速，维护成本低**。

2.  **EC2 集群 (自有资产工厂)：** 这就像您自己购买土地、建造厂房(配置 EC2 实例），并安装了专业的生产设备(ECS 代理).您拥有**完全的控制权**，可以自定义厂房的大小、地点和安全设置(实例类型、磁盘、网络和安全组).但是，**您必须负责**日常的维护、升级和支付所有基础设施的费用。
-->
---
这是一个关于 **如何从零开始建立一个本地 Web Docker 应用并将其部署到 AWS 环境进行验证** 的详细中文解释。这是为后续在 AWS ECS 上进行部署打下基础的重要实战环节。

---

### AWS ECS 容器部署前置实战：本地应用开发与 Docker 化

本次课程的主题是建立一个本地的 Web Docker 应用，并将其部署到 Docker Hub，随后在 AWS EC2 实例上进行远程验证。通过这个过程，我们确认本地开发的容器镜像是可移植且能在云端正常运行的。

#### 1. 技术栈与核心目标

本次构建的 Web 应用采用了以下技术栈：

*   **前端/样式：** Bootstrap 5。
*   **后端/框架：** Express.js (Node.js)。
*   **容器化技术：** Docker。

**核心目标：**
将本地开发、测试成功的 Node.js 应用打包成 Docker 镜像，推送到 **Docker Hub**。后续将部署到 **ECR** (Elastic Container Registry) 上进行管理，以便在部署 ECS 时不需要依赖外部 Docker Hub。

**特殊功能：**
应用中嵌入了自定义代码，能够显示 **正在运行该主机的 IP 地址**。这个功能至关重要，因为今后部署到多台服务器(如通过负载均衡器）时，可以确认当前访问的是哪一个具体的容器或实例。

#### 2. 本地应用搭建步骤(步骤 1 - 2）

首先，需要在本地工作目录中建立 Web 应用程序：

1.  **环境初始化：** 创建工作目录(例如 `ECSweb`），并初始化一个 Node.js 工程。
2.  **安装依赖：** 安装 `express` 库。
3.  **编写入口文件 (`app.js`)：**
    *   引用 Express 框架。
    *   设置一个静态文件目录(`public`），用于存放 `index.html` 和 Bootstrap 等资源。
    *   定义一个 **JSON 路由 (path)**。当用户访问该路径时，应用程序会获取当前运行容器或服务器的 **IP 地址**，并将其显示在画面上。
4.  **编写静态文件：** 创建 `index.html`，展示简单的标题和图片。
5.  **本地运行测试：** 使用 `NPM start`(开发环境可用 `nodemon` 启动）在本地运行 Web 应用。通过访问本地端口 3000 和 JSON 路径，确认应用和 IP 获取功能均正常。

#### 3. Docker 镜像打包与推送(步骤 3 - 4）

在本地应用开发和测试成功后，即可进行容器化：

1.  **编写 Dockerfile：**
    *   引用 **Node.js 14 版本** 作为基础镜像。
    *   设置容器内部的工作文件夹。
    *   将本地配置文件拷贝到镜像中，并执行 `NPM install` 安装依赖库。
    *   将本地应用文件拷贝至镜像。
    *   暴露 **3000 端口**。
    *   定义容器启动命令：运行 `node app.js` 启动 Web 应用。
2.  **打包镜像：** 使用 `docker build` 命令，基于本地的 Dockerfile 打包镜像，并给镜像打上标签(Tag），例如 `深学 AWS-ECSweb`。
3.  **验证镜像：** 使用 `docker images` 命令确认镜像已成功生成，并检查其大小(例如 127 兆).
4.  **推送到 Docker Hub：** 确保本地已登录 Docker Hub 账号。使用 `docker push` 命令将本地镜像推送到 Docker Hub 上的公有仓库。完成后，刷新 Docker Hub 页面，确认新的镜像已成功上传。

#### 4. 远程 EC2 实例验证(步骤 5）

为了验证该镜像在云环境中是否能够正常运行，我们在 AWS EC2 实例上进行测试：

1.  **准备 EC2 环境：** 启动一个 EC2 实例，并确保其已安装 Docker 服务。
2.  **拉取镜像：** 在 EC2 实例上，使用 `docker pull` 命令从 Docker Hub 上下载刚刚推送的镜像。
3.  **运行容器：** 使用 `docker run` 命令启动容器，并进行端口映射。我们将容器内部的 **3000 端口** 映射到 EC2 主机(Host）的 **80 端口**。
4.  **最终验证：** 通过 EC2 实例的公有 IP 地址和 80 端口进行访问。验证结果显示，Web 应用的访问结果与本地运行的结果**完全一致**。

通过这一系列的开发、打包和远程部署验证，我们确认了所构建的 Docker 镜像具备在 AWS 任何环境中运行的能力，为后续的 ECS 部署打下了坚实的基础。

<!--### 总结比喻

我们可以将这个完整的流程比作**制造和运输一架新型无人机**：

1.  **本地应用开发 (Local Development):** 就像在自家车库里设计、组装和调试无人机的**原型机**(Web App).我们确保原型机(在本地 3000 端口）能够正常飞行，并且独特的 IP 显示功能(显示正在飞行的无人机的序列号）也工作正常。
2.  **定义 Dockerfile 与打包 (Dockerfile & Build):** 这就像为原型机设计**标准化的包装箱**(Dockerfile），明确规定了无人机的运行环境(Node 14）、启动指南和需要开放的接口(3000 端口).然后，我们将原型机装入这个标准化的包装箱，形成一个**可运输的产品**(Docker 镜像).
3.  **推送到 Docker Hub (Push to Docker Hub):** 这就像将标准化包装的产品送往一个**国际航运中心/仓库**(Docker Hub).现在，世界上任何地方都可以根据这个标准，取出这个产品。
4.  **远程 EC2 验证 (Remote EC2 Verification):** 这就像在远方的一个**临时机场**(EC2 实例），我们取回包装箱(Pull 镜像），然后将无人机从箱中取出并在机场跑道(EC2 端口 80）上进行试飞。如果它在远方机场的飞行表现与在自家车库的测试结果完全一致，就证明我们的产品(Docker 镜像）是**可靠和可部署的**。
-->
---
本次课程的主题是关于 **AWS ECS Fargate 启动模式下的任务定义 (Task Definition) 与运行验证**。任务定义是部署容器服务之前，用来规划服务所使用的容器、参数和资源配置的关键步骤。

### 1. 任务定义的意义与类型选择

**任务定义的意义：**
任务定义 (Task Definition) 的作用是指定如何部署您的服务，包括需要使用哪些容器镜像、这些容器包含的内容、以及需要指定哪些运行参数。这是在您将业务逻辑打包成镜像(即完成容器定义）之后，进行实际部署前必须完成的规划工作。

**启动类型选择：**
本次实战选择 **Fargate 启动类型** 来创建任务定义。讲师表示，后续课程会演示如何创建 EC2 启动类型。

### 2. 定义 Fargate 任务(Task Definition Setup）

进入 AWS 管理控制台的 ECS 服务，选择“任务定义”，然后创建新任务定义，并选择 **Fargate 类型**。

#### A. 基础配置与角色

1.  **任务命名与兼容性：** 设定任务名称(例如：`深学 AWECSYb发给et topk`），并确认兼容性为 Fargate。
2.  **任务执行角色 (Task Execution Role)：** 选择事先定义好的 IAM 角色，例如 `深学 AWSECS任务执行角色`。
3.  **网络模式 (Network Mode)：** 对于 Fargate 模式，网络模式只能选择 **AWSVPC**。
4.  **任务执行角色 (Execution Role)：** 这个角色是根据您的任务内容来赋予权限的。例如，如果任务需要连接 DynamoDB 或存取 S3，则必须在这里定义相应的权限。

#### B. 资源配置(Fargate 优势）

由于采用 Fargate 模式，配置的资源有更低的起点要求：

*   **内存 (Memory)：** 最小可以选择 **0.5 GB**。如果是 EC2 模式，最小必须选择 1 GB。
*   **CPU：** 最小可以选择 **0.25 个 CPU**。如果是 EC2 模式，最小必须选择 1 个 CPU。
*   本次演示选择了 0.5G 内存和 0.25 CPU。

### 3. 定义容器(Container Definition）

任务定义的核心是指定它将运行哪些容器。

1.  **添加容器：** 任务可以运行多个容器，但本次仅指定运行一个。
2.  **容器名称：** 设定容器名称，例如 `doker深学 AWECS做口`。
3.  **镜像来源 (Image Source)：** 指定容器镜像的来源。本次从上期推送的 **Docker Hub** 公有仓库中获取镜像。
4.  **端口映射 (Port Mapping)：** 这是关键步骤。将容器内部的 **80 端口** 映射到主机(Host）的 **80 端口**。
5.  **环境变量 (Environment Variables)：** 由于 Node.js Express 默认在 3000 端口运行(如果未设置环境端口号），为了配合上面的 80 端口映射，**必须**在环境变量位置添加一个 `PORT` 变量，并赋值为 **80**。这样，应用就会在容器内部的 80 端口运行，并通过端口映射暴露出来。
6.  **日志输出：** 保持默认设置。讲师强调，在生产环境中，**日志输出是必须勾选的好习惯**。
7.  **完成：** 跳过服务集成和代理集成，点击创建，生成任务定义(带有修订版本号 `1`).这个修订版本号提供了任务定义的版本管理功能。

### 4. 运行和验证任务(Running and Verification）

任务定义完成后，可以有多种启动方式(通过服务启动或直接运行任务).本次演示选择**直接运行新任务**进行验证。

1.  **选择集群与任务数：** 选择预先创建的 Fargate 集群。本次演示为了节省资源，仅启动 **一个任务**。
2.  **网络配置：**
    *   **VPC 和子网：** 必须选择能够被外部访问到的 **公有子网**(例如 `外网 EA`）进行部署。
    *   **安全组 (Security Group)：** 选择预先定义好的安全组，该安全组必须开放 **80 端口**，以允许外部访问 Web 应用程序。
    *   **公有 IP (Public IP)：** **必须启用自动分配公有 IP**，否则外部将无法访问该任务。
3.  **启动任务：** 添加标签(好习惯），然后运行任务。
4.  **验证结果：**
    *   任务启动需要等待不到一分钟，状态会变为“可运行”。
    *   任务启动后，ECS 会为其分配一个 **公有 IP 地址**。
    *   通过浏览器访问该公有 IP 地址的 80 端口。
    *   **结果确认：** 访问结果与本地调试的结果完全一致。
    *   **JSON 验证：** 访问应用程序中定义的隐藏 JSON 路径，成功获得了当前正在运行的 Fargate 任务的**内部 IP 地址信息**(属于 10 网段的私有 IP），证明该容器镜像在云端完全正常工作。

<!--### 总结比喻

我们可以将 **建立 Fargate 任务定义** 比作**为公司签订一份标准化、高度自动化的工作合同**：

1.  **任务定义 (Task Definition):** 这就像一份**详细的工作合同**。合同中明确规定了这份工作(Web 应用）需要多少资源(0.5G 内存/0.25 CPU），以及它需要哪些权限(任务执行角色，例如访问 S3 的权限).
2.  **容器定义 (Container Definition):** 这就像合同中指定的**具体的工作内容和工具**。您指定了工作地点(从 Docker Hub 获取镜像），并强调工作成果必须通过 80 号窗口(端口）交付，并且必须使用 80 号工位(环境变量 `PORT=80`），以确保与外部交付流程一致。
3.  **Fargate 模式 (AWS VPC):** 这份合同指定工作必须在 **全托管的高级写字楼** (Fargate/AWS VPC) 中执行。您无需关心桌子、椅子、电源(底层 EC2），只需要把工人(容器）放进去。
4.  **运行任务 (Run Task):** 这就像将合同投入执行，并给这个临时的工人分配一个**临时联系电话**(公有 IP).

最终，通过拨打这个临时电话(访问公有 IP），确认工人(容器）不仅成功启动，而且提供的服务和报告的内部信息(JSON IP）与本地测试时完全一致，证明这份工作合同和流程定义是成功的。
-->
---
本次课程的主题是关于如何 **运行 Fargate 服务 (Fargate Service)**。在上期课程中，我们学习了如何定义 Fargate 任务 (Task) 并直接运行它进行验证。而本期的重点是采用更正规的部署方式：使用 **Fargate 服务** 来运行上期定义的任务。

以下是运行 Fargate 服务及其优势的详细步骤和解释：

### 1. 建立 Fargate 服务 (Service)

Fargate 服务的作用是**以微服务 (Microservice) 的方式**发出并运行任务，同时提供维护和监控功能。

#### 部署配置

1.  **选择启动类型：** 必须选择 **Fargate**。
2.  **选择任务定义：** 使用上期已经定义好的 Fargate 任务定义及其版本。
3.  **集群选择：** 部署到预先建立的 Fargate 集群中。
4.  **服务命名：** 设定服务名称，例如 `深学 AWECSweb发给的 service`。
5.  **任务数量 (Task Count)：** 本次演示定义运行 **两个任务 (Task)**。这意味着在一个服务当中，将默认启动两个 Fargate 容器实例。
6.  **部署类型：**
    *   演示选择 **滚动更新 (Rolling Update)**。这种方式的成本较低，但在更新时可能导致一部分服务器是新的，一部分是旧的。
    *   对于资金充裕或要求高的生产环境，建议采用 **蓝绿部署 (Blue/Green Deployment)**。蓝绿部署会重新生成一套完整的新部署集群，完成后再进行 DNS 切换，效果非常好但成本较高。

#### 网络和资源配置

*   **VPC 和子网：** 选择现有的 `深学 AWSVPC`，并部署到两个**外部(公有）子网**(例如 `外部EA` 和 `外bEC`）中，以便外部能够访问。
*   **安全组：** 选择允许 **80 端口** 访问的安全组。
*   **公有 IP：** **必须启用自动分配公有 IP**，否则外部无法访问该服务。
*   **负载均衡和自动扩展：**
    *   在生产环境中，**负载均衡器 (Load Balancer)** 是必须采用的，但本次演示暂不启用。
    *   **Autoscaling (自动扩展)** 技术也未启用，但它在流量大增(如促销期间）时非常重要，可以根据需求自动将任务数从两个扩展到四个或八个。

7.  **创建服务：** 完成最终审核后，点击创建服务。

### 2. 运行与高可用性验证

服务创建后，需要等待几十秒，两个任务会从 **provation (准备阶段)** 变为 **运行中 (running)**。

1.  **独立访问验证：**
    *   通过点击任务，可以查看每个任务(例如 ID 为 2 和 3 的任务）分配到的 **公有 IP**。
    *   分别通过这两个公有 IP 访问 Web 应用程序，确认两者都能正常响应。
2.  **多可用区验证 (Multi-AZ)：** 通过访问应用程序中定义的隐藏 JSON URL。
    *   可以发现两个任务分配到了不同的内部 IP 地址(例如一个在 10 网段，另一个在 11 IP).
    *   这证明 Fargate 服务自动将两个任务部署在了不同的**可用区**(例如一个在 `webEA`，一个在 `webEC`），从而实现了 **高可用性**。

### 3. 服务的关键优势：自动任务维护

Fargate 服务的核心价值在于其对任务数量的持续监控和维护。

1.  **模拟任务失败：** 演示手动停止一个正在运行的任务(例如停止任务 2），模拟任务发生意外、程序出错或内存溢出导致停止的情况。
2.  **自动恢复：** 服务端会立即监控到停止的任务。在手动停止任务 2 后的不到 5 秒钟内，Fargate 服务就会自动帮用户**重新启动一个新的任务**(例如任务 B).
3.  **结果：** 无论任务是手动停止还是自动抛错停止，服务都会将任务数量维持在定义好的 **两个**。这确保了服务的持续可用性。新启动的任务 B 同样能通过其新的公有 IP 正常访问。

### 4. 最佳实践：立即停止服务

讲师强调，在理解了 Fargate 服务的优势后，**必须立即停止和删除服务**。

*   **原因：** 服务在后台会**永远运行**，并持续产生费用。
*   **教训：** 讲师分享了自己曾忘记在周五下班时停止服务，导致客户白白支付了周末两天的费用的经历，强调这是一个必须养成的良好习惯。
*   **操作：** 进入服务的 `tag` 选项，点击删除服务。

<!--### 总结比喻

我们可以将 **运行 Fargate 服务** 比作**聘请一位全自动、尽职尽责的“乐高积木维护经理”**：

1.  **任务 (Task)** 就像一栋栋正在搭建的乐高积木建筑。
2.  **服务 (Service)** 就像这位 **24/7 全天候工作的维护经理**。您告诉他：“我需要这个大厅里时刻保持 **两栋** 乐高积木建筑在运行(两个任务).”
3.  如果其中一栋积木因为孩子不小心撞倒了(**模拟任务失败**），维护经理会立即检测到积木数量少于两栋，他不会等待您的指令，而是会**立刻从仓库中拿出一个新的积木包，并迅速搭建出一栋新的建筑**(**自动重启任务**).
4.  这位经理确保大厅里的积木数量永远保持在您预设的最低值，从而实现了 **无人值守的高可用性和故障容错**。
-->
---
本次课程的主题是关于如何使用 **AWS ECS 的 EC2 启动类型** 来定义任务、创建集群，并运行任务和服务进行验证。这是对前面 Fargate 模式学习的补充和对比。

### 1. 建立 EC2 任务定义 (Task Definition)

建立 EC2 版本的任务定义与 Fargate 版本有许多相似之处，但也有关键的不同点。

#### 兼容性和网络模式 

*   **兼容性：** 必须选择 **EC2** 兼容性。
*   **网络模式：** 必须选择 **桥接模式 (Bridge Mode)**。这是标准的本地运行 Docker 时所使用的模式。

#### 资源要求 

EC2 模式的任务定义对资源的要求更高，无法选择 Fargate 那样的低配置：
*   **内存 (Memory)：** 最小要求是 **1 GB**。
*   **CPU (vCPU)：** 最小要求是 **1 个 vCPU**。

#### 端口映射 

*   **特点：** EC2 模式的任务支持将容器内部的端口(例如 3000）映射到主机(EC2 实例）的端口(例如 80).
*   **原理：** 这种模式相当于在 EC2 实例中手动执行 `docker run` 命令，通过 UI 界面完成配置。EC2 模式支持两个端口的映射。

### 2. 创建 EC2 集群 (Cluster Creation)

在运行任务之前，必须先建立 EC2 集群，并配置底层 EC2 实例。

#### 集群和实例配置 

1.  **集群选择：** 选择创建集群的第二种类型，即 **EC2**。
2.  **实例类型和数量：**
    *   **购买模式：** 演示选择按需实例 (On-Demand)。讲师建议在自动扩展 (Autoscaling) 场景下，选择 Spot 实例可能更具经济效益。
    *   **实例类型：** 演示选择了 `medium` 类型，因为讲师经验表明，`T2.micro` 等较小的实例类型可能无法满足 ECS 集群的要求。
    *   **实例数量：** 演示中启动 **一台** 实例(但可以指定多台).
3.  **磁盘大小：** 硬盘 (Disk) 最小不能小于 **30 GB**。
4.  **密钥对：** 由于使用的是管理服务，一般很少通过 SSH 登录 EC2 实例，因此选择不用 SSH 密钥。

#### 网络和安全配置 

*   **VPC 和子网：** 选择现有的 VPC，并将实例部署到 **公开网段(公有子网）**(例如 `webeA`).如果需要运行多任务，可以同时选择多个子网(例如 `webEC`).
*   **公有 IP：** 必须启用公有 IP 分配。
*   **安全组：** 选择预先创建的、开放了 **80 端口** 的安全组(例如 `深学 AWSwebSG`).
*   **容器角色：** 选择当初创建好的容器角色(例如 `深学 AWS`).

创建过程通过 **CloudFormation** 完成。随后，可以在 EC2 后台确认有一台 `medium` 实例正在启动，该实例安装了 ECS 代理，可用 CPU 是 2U，内存是 4G。

### 3. 运行和验证 EC2 任务 (Run Task)

任务定义和集群准备就绪后，可以运行任务进行验证。

1.  **启动任务：** 选择 EC2 集群，选择运行新任务，启动类型选择 **EC2**，任务数设置为 **一个**。
2.  **放置原则：** 对于多任务大集群，可以定义放置原则，例如在各个可用区 (AZ) 之间均衡放置。
3.  **验证：** 任务很快会从 `pending` 变为运行中，因为它相当于在 EC2 实例内部启动一个 Docker 容器，执行了镜像下载和运行的过程。
4.  **访问确认：** 通过任务分配的 **公有 IP** 和映射的 80 端口访问，确认 Web 应用正常运行。

#### 关键发现：EC2 模式下的 IP 地址问题 

*   **问题所在：** 当通过应用程序中定义的隐藏 JSON URL 尝试获取主机的 IP 地址时，系统返回的是 **EC2 实例内部 Docker 容器的 IP 地址**，而不是底层的 EC2 实例的公有 IP。
*   **影响：** 这使得用户无法通过 IP 地址判断任务具体运行在哪一台 EC2 实例上，**缺乏参考意义**。
*   **对比：** 讲师指出，**Fargate 模式没有这个问题**，用户可以通过 IP 地址搜索到实际运行的容器位置。这也是讲师推荐使用 Fargate 的原因之一。

### 4. 运行和停止 EC2 服务 (Run and Stop Service)

运行服务是为了以微服务的方式部署任务，并让系统来维护任务的生命周期。

1.  **创建服务：** 选择 EC2 启动类型，指定 EC2 任务定义，并为服务命名(例如 `深学 AWVSECSwebECoservive`).
2.  **任务数量：** 演示中仍然只给一个任务数。
3.  **部署类型：** 选择 **滚动更新 (Rolling Update)** 模式。讲师推荐在生产环境中使用更稳定的 **蓝绿部署 (Blue/Green Deployment)** 模式，尽管成本更高。
4.  **负载均衡：** 演示中选择不配置负载均衡器，但强烈建议在生产环境中对外暴露服务时使用负载均衡器。
5.  **验证结果：** 服务启动任务后，访问结果与直接运行任务的结果一致，同样存在 IP 地址无法确定底层 EC2 实例的问题。
6.  **维护特点：** **服务会自动维护任务数量**。如果手动停止了服务启动的任务，服务会在后台自动启动一个新任务，以保持任务数不变。
7.  **停止：** 因此，必须选择 **停止服务** 的方式，而不是停止单个任务，才能删除由服务管理的所有任务。

### 5. 清理和讲师建议 

在完成演示和验证后，必须立即进行清理以节省成本：

1.  **停止服务：** 删除创建的服务 (`delete me`)。
2.  **删除集群：** 删除 EC2 集群，因为 EC2 实例是按需收费的，会持续产生费用。删除集群可能需要一段时间来清除残留资源。

**讲师建议：** 尽管 ECS 提供了 EC2 和 Fargate 两种运行模式，但讲师真心推荐企业用户，哪怕多花一点钱，也要使用 **Fargate 模式** 来进行微服务的管理，因为其抽象化程度更高，管理更便捷。


<!--### 总结比喻

我们可以将 **AWS ECS 的 EC2 运行模式** 比作 **“驾驶并管理您自己的集装箱卡车队”**：

1.  **EC2 实例 (Cluster):** 就像您购买和拥有的 **卡车**。您需要关心卡车的型号、油箱大小(CPU/内存）、轮胎磨损(硬盘最小 30G），并为它们聘请司机和维护团队(ECS 代理/EC2 角色).您对其拥有完全控制权。
2.  **EC2 任务定义 (Task Definition):** 就像您为卡车设计的**标准化装载规范**。它规定了集装箱(容器）的尺寸(1GB 内存/1 vCPU）、以及如何将集装箱的门(内部端口 3000）连接到卡车的卸货口(主机端口 80).
3.  **运行任务/服务 (Run Task/Service):** 就像让卡车上路运输货物。
4.  **IP 地址问题 (IP Caveat):** 这就像您在路上追踪卡车时，只能看到**集装箱侧面的货物编号**，而**无法直接看到卡车的车牌号码**。虽然货物在动，但您不知道是哪一辆具体的卡车在运送它。

相较而言，Fargate 模式则更像您使用了一个**全自动的物流服务**。您只告诉服务方运什么货物，他们自动提供最合适的车辆，并确保您能随时查询到车辆的准确位置(公有 IP 地址).
-->
---

本次课程的主题是 **深入理解 AWS ECS 的网络模式 (Network Modes)**。这些网络模式的选择对于您如何部署和管理容器至关重要。

在 ECS 任务联网(Task Networking）中，AWS 官方提供了三种主要的网络模式。通过这些模式，您可以决定容器内部的端口如何与底层主机(EC2 实例）的端口进行通信和映射。

以下是这三种模式的详细解释和对比：

### 1. 桥接模式 (Bridge Mode)

**特点：**

*   **本地标准模式：** 桥接模式(Bridge Mode）其实就是 **本地运行 Docker 的标准模式**。
*   **端口映射：** 这种模式允许您将容器内部的端口(例如 3000 端口）**映射到** 主机(EC2 实例）上的**任意一个未被占用的端口**(例如 30001 端口).
*   **端口限制：** 在同一台主机上，如果您运行了多个容器，并且它们都将内部端口映射到主机上，那么 **主机上的端口不能重复**。
    *   例如，如果 `Task 1` 将 3000 端口映射到主机的 30001 端口，那么 `Task 2`(即使它内部也使用了 3000 端口）就不能再映射到 30001 端口，只能映射到其他端口，比如 30002。

**应用场景：** 您可以在一台主机上运行多个容器(或任务），同时允许将容器的端口映射到主机上，但您必须手动管理主机的端口以避免冲突。

### 2. 主机模式 (Host Mode)

**特点：**

*   **端口绑定：** 主机模式(Host Mode）的原理非常简单，它要求容器内部使用的端口号，**必须** 被映射到主机(EC2）上 **完全相同的端口号**。
    *   例如，如果容器内部使用 3001 端口，那么它在 EC2 主机上必须使用 3001 端口。
*   **局限性：** 这种模式有两大限制：
    1.  它**不能进行端口映射**(即端口号必须保持一致).
    2.  它**不能运行相同任务**，因为主机上的端口是不能重复占用的。如果您有两个容器都想使用 3001 端口，但主机模式下，3001 端口一旦被第一个容器占用，第二个容器就无法启动。

**活用点：** 这种模式相对容易理解，因为容器内和容器外的端口号是完全一致的。

### 3. AWSVPC 模式 (Fargate 专用模式)

**特点：**

*   **Fargate 专用：** AWSVPC 模式是 **Fargate 专用的模式**。
*   **解决了冲突问题：** 这种模式解决了桥接模式和主机模式中存在的端口冲突问题。
*   **工作原理——多网卡 (ENI)：** AWSVPC 模式通过利用 **弹性网络接口 (ENI, Elastic Network Interface)** 的特性来实现的。
    *   在运行这种模式时，AWS 会在 EC2 实例(或 Fargate 抽象层）上安装 **多个网卡**。
    *   **每个网卡** 都会绑定一个 **容器**(或任务).
    *   每个网卡可以有自己的 **独立 IP 地址**。
    *   由于每个容器都有了自己的独立 IP 地址，**即使两个容器都使用相同的端口号**(例如 80 端口），它们也不会冲突。因为它们实际上是通过不同的网卡和不同的 IP 地址暴露出来的。

**优势：** AWSVPC 模式的最大好处在于，容器内部使用哪个端口，它几乎就可以将原端口映射到主机上来，并且相同的端口号并不会冲突。这使得服务部署更加灵活和便捷。



<!--### 总结比喻

我们可以将这三种 ECS 网络模式比作 **在同一栋大楼(EC2 实例）中开设不同的餐厅(容器）**，并管理它们的出入口(端口）：

1.  **桥接模式 (Bridge Mode):** 就像您在大楼的每个餐厅(容器）内部都有一个服务窗口(3000 端口).但由于大楼的外部只有一个大通道(主机端口），您必须为每个餐厅指定一个**唯一的外部接待窗口号**(30001、30002 等），确保客户不会跑错地方。您必须手动协调这些外部窗口号，不能重复。

2.  **主机模式 (Host Mode):** 就像大楼要求餐厅的内部窗口号和外部接待窗口号**必须完全一样**(例如都用 3001 端口).更重要的是，由于外部通道是共享的，所以**整栋大楼中只能有一个餐厅使用 3001 端口**。这极大地限制了您可以开设餐厅的数量。

3.  **AWSVPC 模式 (Fargate 专用):** 这就像大楼的每个餐厅都被分配了**自己独立的出入口通道和门牌号(ENI 和 IP 地址）**。因为每个餐厅都有了自己的独立基础设施，所以**所有餐厅都可以同时将自己的主服务窗口命名为“80 号”**，它们不会互相冲突。客户只需要知道餐厅的独特门牌号(IP 地址），即可准确找到并访问 80 号窗口。
-->
---
好的，本次课程的主题是关于 **如何在 AWS ECS Fargate 模式下，结合使用弹性负载均衡器 (ELB) 来分流后端任务流量**。

在微服务架构中，当您运行多个 Fargate 任务(或微服务）时，不能直接将每个任务的独立 IP 地址暴露给客户。正确的做法是使用一个标准的 URL 地址，而 **ELB(负载均衡器）** 技术正是实现这一目的的关键框架。

以下是实现这一标准微服务架构(ELB + ECS Fargate）的详细步骤和原理：

### 1. 微服务架构与 ELB 的作用

在一个标准的微服务架构中，流量流向如下：

*   用户通过 Internet 访问前端的 **负载均衡器 (ELB)**。
*   ELB 根据用户的请求、IP 地址和负载情况，将请求动态导航至后端的 **ECS Fargate 任务**。
*   后端 Fargate 任务接收请求，进行业务处理(例如访问 DynamoDB 或其他资源），并将计算结果返回给用户。
*   如果只有一位用户，ELB 可能只导向一台 Fargate 微服务。但如果同时有**上百万级**的请求，ELB 会非常忙碌，它会动态地将这些请求转发给后端的多个 Fargate 服务。
*   暴露给用户的，始终是前端 ELB 的地址，而不是每一个 Fargate 任务的独立 IP。

### 2. 实战演习步骤概览

讲师将整个实战过程分为五步：

1.  **建立目标群组 (Target Group)**。
2.  **建立负载均衡器 (ELB)**。
3.  **重新定义并启动 Fargate 任务服务**。
4.  **动作确认与验证**。
5.  **清理现场**(因为每一步操作都会产生费用).

### 3. 创建前置资源：目标群组 (Target Group)

在创建负载均衡器之前，AWS 目前的设计有一个“小问题”(讲师称之为 Bug）：您必须先指定一个目标群组，负载均衡器才能创建。

*   **操作：** 搜索 EC2，进入“目标群组”，创建一个目标组。
*   **模式：** 选择 **实例 (Instance)** 类型(虽然最终会用于 Fargate).
*   **命名与端口：** 命名为 `TGECSFarget`，端口设置为 **80**。
*   **注意：** **这个目标组只是为了创建 ELB 而创建的**，最终会通过 ECS 控制台重新建立真正需要的 Fargate 目标组，所以这个初始目标组是“根本不用”的。

### 4. 创建负载均衡器 (ELB)

接下来创建实际的负载均衡器(ALB - Application Load Balancer).

*   **类型：** 选择 **ALB**。
*   **可见性：** 必须面向 **互联网 (Internet-facing)**。
*   **VPC 和子网：** 选择现有的 VPC。ELB **必须跨多个 AZ (Availability Zone)** 运行以确保高可用性，因此选择两个不同的子网(例如 `webEA` 和 `webEC`），并且这些子网必须是**可以通向 Internet** 的公开网段。
*   **安全组：** 选择预先定义好的 **ALB 安全组**，该安全组为用户开放了 **80 和 443 端口**。
*   **转发目标：** 在创建时，由于设计限制，必须选择上一步创建的那个“无用”目标组。
*   **后续清理：** ELB 创建成功后处于 `Provisioning` 阶段。一旦运行起来，**必须删除其默认的监听器**(因为后续 ECS 会通过自己的控制台重新建立监听器).

### 5. 创建 Fargate 服务与集成 ELB

现在，使用 ELB 来运行 ECS Fargate 服务。讲师强烈推荐使用 Fargate 模式，而不是 EC2。

*   **创建服务：** 选择 Fargate 集群，创建新服务。
*   **任务数量：** 演示中设置为运行 **两个任务 (Task)**。
*   **部署类型：** 选择 **滚动更新 (Rolling Update)**，但在生产环境中建议使用成本更高的 **蓝绿部署 (Blue/Green Deployment)**。
*   **网络配置 (AWSVPC)：**
    *   将服务部署到公开网段的多个子网中(例如 `webEC` 和 `webEA`），这样服务就会被动态分配到不同的 AZ 区，实现高可用性。
    *   **安全组：** 选择 ALB 的安全组。**注意：** 在生产环境中，安全组的来源(Source）**应该限制为仅允许 ALB 访问**，而不是像演示中那样选择“所有 IP”。
    *   **公有 IP：** 启用公有 IP 分配(用于验证).
*   **负载均衡器集成 (关键步骤)：**
    *   选择上一步创建的 **ALB**。
    *   **端口：** 选择任务定义中已经设置好的 **80 端口**。
    *   **目标组创建：** 在这里，才是真正新建 **Fargate 专用的目标组**。选择新建目标组，并命名(例如 `深学 AWVSfargetsurvice TG`），协议设置为 **HTTP**(因为 SSL/HTTPS 应该是 ELB 的工作).
*   **自动扩展：** 演示中不启用，但生产环境通常需要启用。

### 6. 验证与确认

服务创建后，两个任务很快会进入 `running` 状态。

1.  **独立 IP 验证：** 验证两个任务分别获得了不同的公有 IP。通过访问这些 IP，可以看到 Web 应用正常运行。通过隐秘的 JSON 路径验证，发现这两个任务被分配到了不同的网段(例如 10 网段和 11 网段），证明它们被部署在了不同的 **AZ 区域**和不同的子网中。
2.  **ELB 访问验证(正根）：**
    *   通过访问 **ELB 的 DNS 名称**，可以成功访问到 Web 应用。
    *   **这是向用户暴露服务的真正正确方式**。
    *   **最佳实践：** 应该在 **Route 53** 中设置一个公司自己的服务 URL，并将其设置为 ELB 的别名记录，然后将这个 URL 暴露给用户。
3.  **负载均衡验证：** 通过不断刷新 ELB 的 DNS 名称并访问 JSON 路径，可以观察到后端服务的 IP 地址在 10 网段和 11 网段之间来回切换(负载均衡器正在导航），尽管为了提高效率，可能会在短时间内持续导向同一台服务器。

### 7. 结论与最佳实践

*   **ELB + ECS Fargate 模式** 是 AWS 推荐的 **最佳实践 (Best Practice)**。
*   该技术在生产环境中是首推的部署方式。
*   **清理：** 讲师再次强调，必须在实验完成后立即清理资源以避免产生不必要的费用。

---

<!-- ### 总结比喻

我们可以将 **ELB 与 ECS Fargate 的结合** 比作 **一家配备了智能交通指挥系统的物流中心**：

1.  **Fargate 任务 (Tasks):** 就像一个个独立的、能够执行特定任务的**小型配送站点**(微服务).它们各自有自己的内部地址(私有 IP).
2.  **ELB (负载均衡器):** 就像物流中心设立的**统一对外服务热线**。客户永远只拨打这一个热线号码(ELB 的 DNS 名称).
3.  **热线的工作原理：** 当有大量订单(上百万请求）涌入时，热线会**智能地判断**哪个配送站(Fargate Task）最空闲，或者距离客户最近，然后自动将订单分配给它。
4.  **目标组 (Target Group):** 就像热线系统内部的**配送站地址名录**。只有被列入名录的站点，才能接收到热线分配的订单。
5.  **最终结果：** 客户不需要知道成百上千个配送站的具体地址(Fargate IP），他们只需要知道那一个统一的热线号码，就能保证他们的订单能够被最快、最稳定地处理，即使某个配送站临时出现故障，热线也会自动转向另一个正常的站点，确保服务不会中断。
-->




